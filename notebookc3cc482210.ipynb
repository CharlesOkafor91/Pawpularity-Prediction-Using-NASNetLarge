{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n#keras\nimport tensorflow.keras as keras\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.layers import Input, Dense, Dropout, Activation, Flatten, BatchNormalization\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D\nfrom tensorflow.keras.optimizers import Adam\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        file_path = os.path.join(dirname, filename)\n        #print(os.path.join(dirname, filename))\n        \n\ndataset_path = '/kaggle/input/petfinder-pawpularity-score/'\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-12-16T07:09:07.835337Z","iopub.execute_input":"2021-12-16T07:09:07.836023Z","iopub.status.idle":"2021-12-16T07:09:15.313557Z","shell.execute_reply.started":"2021-12-16T07:09:07.835915Z","shell.execute_reply":"2021-12-16T07:09:15.312582Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"# **Taking a look at the Data - (EDA)**","metadata":{}},{"cell_type":"code","source":"train_df = pd.read_csv(dataset_path + 'train.csv')\ntest_df = pd.read_csv(dataset_path + 'test.csv')\nsubmission_df = pd.read_csv(dataset_path + 'sample_submission.csv')\n\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-16T07:09:19.804320Z","iopub.execute_input":"2021-12-16T07:09:19.804889Z","iopub.status.idle":"2021-12-16T07:09:19.867383Z","shell.execute_reply.started":"2021-12-16T07:09:19.804852Z","shell.execute_reply":"2021-12-16T07:09:19.866500Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"submission_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-16T07:09:22.567537Z","iopub.execute_input":"2021-12-16T07:09:22.568001Z","iopub.status.idle":"2021-12-16T07:09:22.579085Z","shell.execute_reply.started":"2021-12-16T07:09:22.567962Z","shell.execute_reply":"2021-12-16T07:09:22.578304Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"test_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-16T07:09:25.967028Z","iopub.execute_input":"2021-12-16T07:09:25.967679Z","iopub.status.idle":"2021-12-16T07:09:25.989038Z","shell.execute_reply.started":"2021-12-16T07:09:25.967633Z","shell.execute_reply":"2021-12-16T07:09:25.988251Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Add image path to the dataset\n\ntrain_df['Img'] = train_df['Id'].map(lambda x: str(dataset_path + 'train/' + x + '.jpg'))\n# train_df = train_df.drop(columns=['Id']) - keeping the ID of the test data. Would be useful for submission\n\ntest_df['Img'] = test_df['Id'].map(lambda x: str(dataset_path + 'test/' + x + '.jpg'))\n# test_df = test_df.drop(columns=['Id']) - keeping the ID of the test data. Would be useful for submission\n\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-16T07:09:29.103419Z","iopub.execute_input":"2021-12-16T07:09:29.103968Z","iopub.status.idle":"2021-12-16T07:09:29.132008Z","shell.execute_reply.started":"2021-12-16T07:09:29.103928Z","shell.execute_reply":"2021-12-16T07:09:29.131326Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"**Checkiing out the distribution of the target variable - Pawpularity**","metadata":{}},{"cell_type":"code","source":"train_df['Pawpularity'].describe()","metadata":{"execution":{"iopub.status.busy":"2021-12-16T07:09:31.727719Z","iopub.execute_input":"2021-12-16T07:09:31.728255Z","iopub.status.idle":"2021-12-16T07:09:31.744862Z","shell.execute_reply.started":"2021-12-16T07:09:31.728213Z","shell.execute_reply":"2021-12-16T07:09:31.743897Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"train_df['Pawpularity'].hist(figsize=(10,5))","metadata":{"execution":{"iopub.status.busy":"2021-12-16T07:09:34.921071Z","iopub.execute_input":"2021-12-16T07:09:34.921871Z","iopub.status.idle":"2021-12-16T07:09:35.354650Z","shell.execute_reply.started":"2021-12-16T07:09:34.921821Z","shell.execute_reply":"2021-12-16T07:09:35.353973Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"The above looks skewed","metadata":{}},{"cell_type":"markdown","source":"**Checking to see the distribution**","metadata":{}},{"cell_type":"code","source":"sns.set(rc={'figure.figsize':(14,9)})\n\nfig = plt.figure()\nsns.histplot(data=train_df, x='Pawpularity', kde=True)\nplt.axvline(train_df['Pawpularity'].mean(), c='green', ls='-', lw=3, label=\"Mean Pawpularity\")\nplt.title('Pawpularity score Histogram', fontsize=20, fontweight='bold')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-16T07:09:40.301942Z","iopub.execute_input":"2021-12-16T07:09:40.302226Z","iopub.status.idle":"2021-12-16T07:09:40.782722Z","shell.execute_reply.started":"2021-12-16T07:09:40.302177Z","shell.execute_reply":"2021-12-16T07:09:40.782041Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"This is not sufficient to say if the data is normally distributed as it is centered around 38. We will check the normality of the distribution with a quantile - quantile diagram.","metadata":{}},{"cell_type":"code","source":"from statsmodels.graphics.gofplots import qqplot\n\nfig = plt.figure()\nqqplot(train_df['Pawpularity'], line='s')\nplt.title('Quantile-Quantile plot of Pawpularity distribution')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-16T07:09:44.786877Z","iopub.execute_input":"2021-12-16T07:09:44.787367Z","iopub.status.idle":"2021-12-16T07:09:45.197693Z","shell.execute_reply.started":"2021-12-16T07:09:44.787328Z","shell.execute_reply":"2021-12-16T07:09:45.197002Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"From the QQPlot above, we can also see the target column is not normally distributed. We will now check with the Kolmogorov-Smirnov test to further confirm","metadata":{}},{"cell_type":"code","source":"from scipy.stats import kstest\n\nstat, p = kstest(train_df['Pawpularity'],'norm')\nprint('Statistics=%.3f, p=%.3f' % (stat, p))\n# interpret\nalpha = 0.05\nif p > alpha:\n    print(f'Data seem Gaussian. We will not reject H0 at {int(alpha*100)}% test level')\nelse:\n    print(f'Data is not Gaussian We will reject H0 at {int(alpha*100)}% test level')","metadata":{"execution":{"iopub.status.busy":"2021-12-16T07:09:48.645365Z","iopub.execute_input":"2021-12-16T07:09:48.646112Z","iopub.status.idle":"2021-12-16T07:09:48.655491Z","shell.execute_reply.started":"2021-12-16T07:09:48.646065Z","shell.execute_reply":"2021-12-16T07:09:48.654574Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"**Let us now take a look at the distribution of the rest of the parameters**","metadata":{}},{"cell_type":"code","source":"train_df.info()","metadata":{"execution":{"iopub.status.busy":"2021-12-16T07:09:51.528567Z","iopub.execute_input":"2021-12-16T07:09:51.529095Z","iopub.status.idle":"2021-12-16T07:09:51.548760Z","shell.execute_reply.started":"2021-12-16T07:09:51.529055Z","shell.execute_reply":"2021-12-16T07:09:51.547882Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"**There are no missing values**","metadata":{}},{"cell_type":"code","source":"predictor = train_df.columns[1:-2]\n\nfig = plt.figure(figsize=(25,20))\nfor i, x in enumerate(predictor):\n    ax = plt.subplot(3,4,i+1)\n    sns.countplot(data=train_df, x=x, ax=ax)\n    ax.set_xlabel(None)\n    ax.set_title(x, fontweight='bold', color=\"#e7323f\")\n\nplt.suptitle(\"Predictor distribution\", y=0.93,\n             fontsize=20, fontweight='bold')\nplt.show()  ","metadata":{"execution":{"iopub.status.busy":"2021-12-16T07:09:55.411581Z","iopub.execute_input":"2021-12-16T07:09:55.412060Z","iopub.status.idle":"2021-12-16T07:09:56.643114Z","shell.execute_reply.started":"2021-12-16T07:09:55.412024Z","shell.execute_reply":"2021-12-16T07:09:56.642282Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# Lets take a look at the heatmap of the dataset\nfig, ax = plt.subplots(figsize=(18, 18))\nsns.heatmap(train_df[:-1].corr(),annot=True)","metadata":{"execution":{"iopub.status.busy":"2021-12-16T07:10:00.680344Z","iopub.execute_input":"2021-12-16T07:10:00.681029Z","iopub.status.idle":"2021-12-16T07:10:01.971786Z","shell.execute_reply.started":"2021-12-16T07:10:00.680992Z","shell.execute_reply":"2021-12-16T07:10:01.971060Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"From the above, we can see there is a bit of high correlation (>0.5) between Eyes and Face, and Occlusion and Human. Info and Collage also come close but not up to 0.5\n\nWe, therefore also need to check if there is too much multicollinearity that could degrade the performance of our models. For this we will use Variance Inflation Factor (VIF) from Statsmodel","metadata":{}},{"cell_type":"code","source":"from statsmodels.stats.outliers_influence import variance_inflation_factor\n\nvif = pd.DataFrame()\nX = train_df[predictor]\nvif[\"Feature\"] = X.columns\n  \n# calculating VIF for each feature\nvif[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(len(X.columns))]  \nvif = vif.sort_values(\"VIF\", ascending=False)\nvif","metadata":{"execution":{"iopub.status.busy":"2021-12-16T07:10:08.855978Z","iopub.execute_input":"2021-12-16T07:10:08.856883Z","iopub.status.idle":"2021-12-16T07:10:08.995081Z","shell.execute_reply.started":"2021-12-16T07:10:08.856833Z","shell.execute_reply":"2021-12-16T07:10:08.994275Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"From the table above, Face and Eyes have very high values of VIF, which means both parameters are highly correlated. Hence, having the 2 pramters together in our model will lead to a model with high multicollinearity. To avoid this, we will have to use only one of the 2 parameters.\n\nWe remove the column(Parameter) with the highest VIF.","metadata":{}},{"cell_type":"code","source":"X.drop(\"Face\", axis=1, inplace=True)\nX.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-16T07:10:16.690364Z","iopub.execute_input":"2021-12-16T07:10:16.691164Z","iopub.status.idle":"2021-12-16T07:10:16.711824Z","shell.execute_reply.started":"2021-12-16T07:10:16.691120Z","shell.execute_reply":"2021-12-16T07:10:16.711117Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"**Correlations between predictor variables and Pawpularity**\n\nWe will now check whether there are strong linear correlations (Pearson) between the predictor variables and the variable to be predicted (Pawpularity).","metadata":{}},{"cell_type":"code","source":"for x in X.columns:\n    corr_y = round(np.corrcoef(train_df[x], train_df[\"Pawpularity\"])[0,1],4)\n    print(f\"Pawpularity - {x}: {corr_y}\")","metadata":{"execution":{"iopub.status.busy":"2021-12-16T07:10:23.741316Z","iopub.execute_input":"2021-12-16T07:10:23.741581Z","iopub.status.idle":"2021-12-16T07:10:23.759865Z","shell.execute_reply.started":"2021-12-16T07:10:23.741552Z","shell.execute_reply":"2021-12-16T07:10:23.758919Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"From the above, there seem to be no correlation between the target variable and the other parameters.","metadata":{}},{"cell_type":"markdown","source":"**Taking a look at a sample Images**","metadata":{}},{"cell_type":"code","source":"from PIL import Image\n\nim = Image.open(train_df['Img'][15])\nwidth, height = im.size\nprint(width,height)","metadata":{"execution":{"iopub.status.busy":"2021-12-16T07:10:26.462814Z","iopub.execute_input":"2021-12-16T07:10:26.463366Z","iopub.status.idle":"2021-12-16T07:10:26.476909Z","shell.execute_reply.started":"2021-12-16T07:10:26.463327Z","shell.execute_reply":"2021-12-16T07:10:26.475972Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"im","metadata":{"execution":{"iopub.status.busy":"2021-12-16T07:10:31.516934Z","iopub.execute_input":"2021-12-16T07:10:31.517494Z","iopub.status.idle":"2021-12-16T07:10:31.840520Z","shell.execute_reply.started":"2021-12-16T07:10:31.517455Z","shell.execute_reply":"2021-12-16T07:10:31.830808Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(2,3,figsize=(15,9))\nfig.patch.set_facecolor('#343434')\n\nfor i, a in zip(train_df[['Img', 'Pawpularity']].sample(6).iterrows(), ax.ravel()):\n    a.set(xticks=[], yticks=[])\n    img = plt.imread(i[1][0])\n    a.imshow(img)\n    a.set_title(f'Id: {i[0]}, Pawpularity Score: {i[1][1]}', color=\"white\")\n\nfig.suptitle('Pawpularity Images', fontsize=20, fontweight='bold', color=\"#e7273e\")\nfig.tight_layout()\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-16T07:10:37.758110Z","iopub.execute_input":"2021-12-16T07:10:37.758655Z","iopub.status.idle":"2021-12-16T07:10:38.968593Z","shell.execute_reply.started":"2021-12-16T07:10:37.758618Z","shell.execute_reply":"2021-12-16T07:10:38.966273Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"**Let us look at 3 of the most popular and 3 of the least popular to see if there are any physical difference**","metadata":{}},{"cell_type":"code","source":"top = train_df[train_df['Pawpularity'] == 100]['Img']\ntop","metadata":{"execution":{"iopub.status.busy":"2021-12-16T07:10:45.319526Z","iopub.execute_input":"2021-12-16T07:10:45.319791Z","iopub.status.idle":"2021-12-16T07:10:45.329571Z","shell.execute_reply.started":"2021-12-16T07:10:45.319761Z","shell.execute_reply":"2021-12-16T07:10:45.328595Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"top = train_df[train_df['Pawpularity'] == 100]['Img']\n\nfig, ax = plt.subplots(1,3)\nfig.patch.set_facecolor('#343434')\n\nfor i, ax in zip(top.sample(3), ax.ravel()):\n    ax.set(xticks=[], yticks=[])\n    img = plt.imread(i)\n    ax.imshow(img)\n    \nfig.suptitle('Most Pawpular Images', fontsize=20, color='#7bbfc5', y=0.95)\nfig.tight_layout()\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-16T07:10:51.288965Z","iopub.execute_input":"2021-12-16T07:10:51.289255Z","iopub.status.idle":"2021-12-16T07:10:52.032986Z","shell.execute_reply.started":"2021-12-16T07:10:51.289215Z","shell.execute_reply":"2021-12-16T07:10:52.032335Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"bottom = train_df[train_df['Pawpularity'] == 1]['Img']\n\nfig, ax = plt.subplots(1,3)\nfig.patch.set_facecolor('#343434')\n\nfor i, ax in zip(bottom.sample(3), ax.ravel()):\n    ax.set(xticks=[], yticks=[])\n    img = plt.imread(i)\n    ax.imshow(img)\n    \nfig.suptitle('Least Pawpular Images', fontsize=20, color='#7bbfc5', y=0.95)\nfig.tight_layout()\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-16T07:10:56.676587Z","iopub.execute_input":"2021-12-16T07:10:56.676852Z","iopub.status.idle":"2021-12-16T07:10:57.576275Z","shell.execute_reply.started":"2021-12-16T07:10:56.676823Z","shell.execute_reply":"2021-12-16T07:10:57.575539Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"# Feature Engineering","metadata":{}},{"cell_type":"markdown","source":"Since we are predicting the popularity of pictures, we will therefore extract features that can help determine (increase or decrease) the likeness or popularity of the pictures such as the background or dominant color.\n\nWe will start with extracting the dominant colors of the images and store as a parameter.\nWe will be using clustering methods on the RGB layers of our image files to extract the dominant color in HLS (Hue Lightness Saturation) format. This format will allow us to recover in a single formula the information on the hue, saturation and luminance of the dominant color of each image.","metadata":{}},{"cell_type":"code","source":"from sklearn.cluster import KMeans\nfrom collections import Counter\nimport cv2\n\n\ndef get_dominant_color(image_path, k=4, image_processing_size = None):\n    \"\"\"\n    takes an image as input\n    returns the dominant color of the image as a list\n    \n    dominant color is found by running k means on the \n    pixels & returning the centroid of the largest cluster\n\n    processing time is speed up by working with a smaller image; \n    this resizing can be done with the image_processing_size param \n    which takes a tuple of image dims as input\n    \"\"\"\n    \n    image = plt.imread(image_path)\n    #resize image if new dims provided\n    if image_processing_size is not None:\n        image = cv2.resize(image, image_processing_size, \n                            interpolation = cv2.INTER_AREA)\n    \n    #reshape the image to be a list of pixels\n    image = image.reshape((image.shape[0] * image.shape[1], 3))\n\n    #cluster and assign labels to the pixels \n    clt = KMeans(n_clusters = k)\n    labels = clt.fit_predict(image)\n\n    #count labels to find most popular\n    label_counts = Counter(labels)\n\n    #subset out most popular centroid\n    dominant_color = clt.cluster_centers_[label_counts.most_common(1)[0][0]]\n    dominant_color = list(dominant_color)\n    r = int(dominant_color[0])\n    g = int(dominant_color[1])\n    b = int(dominant_color[2])\n    \n    #Convert to HLS color space\n    dominant_hls = colorsys.rgb_to_hls(r, g, b)\n\n    return list(dominant_hls)","metadata":{"execution":{"iopub.status.busy":"2021-12-16T07:11:21.533783Z","iopub.execute_input":"2021-12-16T07:11:21.534049Z","iopub.status.idle":"2021-12-16T07:11:22.272709Z","shell.execute_reply.started":"2021-12-16T07:11:21.534018Z","shell.execute_reply":"2021-12-16T07:11:22.271947Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"Taking a look at sample Image","metadata":{}},{"cell_type":"code","source":"import colorsys\nimport matplotlib\n\nsample_img = train_df['Img'][103]\nsample_hls = get_dominant_color(sample_img, k=3, image_processing_size = (50, 50))\nsample_dom_color = colorsys.hls_to_rgb(sample_hls[0],\n                                       sample_hls[1],\n                                       sample_hls[2])\nsample_dom_color = \"#{:02x}{:02x}{:02x}\".format(int(sample_dom_color[0]),\n                                                int(sample_dom_color[1]),\n                                                int(sample_dom_color[2]))\nprint(\"Dominant HLS : \", sample_hls)\nprint(\"Dominant Color Hex : \", sample_dom_color)\n\nfig = plt.figure(figsize=(12,5))\nax = fig.add_subplot(121)\nax = plt.imshow(plt.imread(sample_img))\nax2 = fig.add_subplot(122)\nrect1 = matplotlib.patches.Rectangle((0,0), 10, 5,color=sample_dom_color)\nax2.add_patch(rect1)\nplt.axis('off')\nplt.suptitle('Dominant color of sample image', fontsize=20, fontweight='bold', y=0.98)\nfig.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-16T07:11:25.674448Z","iopub.execute_input":"2021-12-16T07:11:25.674722Z","iopub.status.idle":"2021-12-16T07:11:26.290890Z","shell.execute_reply.started":"2021-12-16T07:11:25.674684Z","shell.execute_reply":"2021-12-16T07:11:26.290330Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":"Applying to all images","metadata":{}},{"cell_type":"code","source":"from tqdm.notebook import tqdm\n\ntqdm.pandas()\ntrain_df['Dominant_color_hls'] = train_df['Img'].progress_apply(lambda x: get_dominant_color(x, k=3, image_processing_size = (50, 50)))","metadata":{"execution":{"iopub.status.busy":"2021-12-16T07:11:31.072026Z","iopub.execute_input":"2021-12-16T07:11:31.072590Z","iopub.status.idle":"2021-12-16T07:24:41.703838Z","shell.execute_reply.started":"2021-12-16T07:11:31.072550Z","shell.execute_reply":"2021-12-16T07:24:41.703129Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"train_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-15T11:43:23.125567Z","iopub.execute_input":"2021-12-15T11:43:23.126117Z","iopub.status.idle":"2021-12-15T11:43:23.148379Z","shell.execute_reply.started":"2021-12-15T11:43:23.126079Z","shell.execute_reply":"2021-12-15T11:43:23.147614Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"temp_train_df = train_df[\"Dominant_color_hls\"].apply(pd.Series)\ntemp_train_df = temp_train_df.rename(columns={0:\"H\",1:\"L\",2:\"S\"})\ntrain_df = pd.concat([train_df, temp_train_df], axis=1)\ntrain_df.drop(\"Dominant_color_hls\", axis=1, inplace=True)\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-15T11:43:23.150022Z","iopub.execute_input":"2021-12-15T11:43:23.150383Z","iopub.status.idle":"2021-12-15T11:43:25.065777Z","shell.execute_reply.started":"2021-12-15T11:43:23.150334Z","shell.execute_reply":"2021-12-15T11:43:25.065077Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Looking at the distribution of H, L, S","metadata":{}},{"cell_type":"code","source":"fig = plt.figure(figsize=(20,6))\nax1 = fig.add_subplot(131)\nsns.histplot(train_df[\"H\"], ax=ax1)\nax1.set_title(\"Hue\", fontsize=17, color=\"#186fb4\")\nax2 = fig.add_subplot(132)\nsns.histplot(train_df[\"L\"], ax=ax2)\nax2.set_title(\"Luminance\", fontsize=17, color=\"#186fb4\")\nax3 = fig.add_subplot(133)\nsns.histplot(train_df[\"S\"], ax=ax3)\nax3.set_title(\"Saturation\", fontsize=17, color=\"#186fb4\")\nplt.suptitle('Dominant HLS color of train images', \n             fontsize=20, fontweight='bold', y=0.98)\nfig.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-15T11:43:25.070095Z","iopub.execute_input":"2021-12-15T11:43:25.07068Z","iopub.status.idle":"2021-12-15T11:43:26.364941Z","shell.execute_reply.started":"2021-12-15T11:43:25.070647Z","shell.execute_reply":"2021-12-15T11:43:26.364228Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df[\"Dominant_color_hls\"] = test_df[\"Img\"].progress_apply(\n    lambda x : get_dominant_color(\n        x, \n        k=3, \n        image_processing_size = (50, 50)))","metadata":{"execution":{"iopub.status.busy":"2021-12-15T11:43:26.368888Z","iopub.execute_input":"2021-12-15T11:43:26.37096Z","iopub.status.idle":"2021-12-15T11:43:27.304418Z","shell.execute_reply.started":"2021-12-15T11:43:26.370919Z","shell.execute_reply":"2021-12-15T11:43:27.303884Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"temp_test_df = test_df[\"Dominant_color_hls\"].apply(pd.Series)\ntemp_test_df = temp_test_df.rename(columns={0:\"H\",1:\"L\",2:\"S\"})\ntest_df = pd.concat([test_df, temp_test_df], axis=1)\ntest_df.drop(\"Dominant_color_hls\", axis=1, inplace=True)\ntest_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-15T11:43:27.307326Z","iopub.execute_input":"2021-12-15T11:43:27.307763Z","iopub.status.idle":"2021-12-15T11:43:27.335713Z","shell.execute_reply.started":"2021-12-15T11:43:27.307729Z","shell.execute_reply":"2021-12-15T11:43:27.335089Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Resizing Images**\n\nWe will have to perform resize to obtain input_shape conforming to what the models we will be running expect. We are therefore going to save the initial size of the image in a variable. This could also have an impact on the popularity of the photo.","metadata":{}},{"cell_type":"code","source":"def get_img_size(path):\n    width = []\n    height = []\n    landscape = []\n    for image_path in tqdm(os.listdir(path)):\n        image = plt.imread(path+image_path)\n        width.append(image.shape[1])\n        height.append(image.shape[0])\n        if(image.shape[1] > image.shape[0]):\n            landscape_img = 1\n        else:\n            landscape_img = 0\n        landscape.append(landscape_img)\n    return width, height, landscape","metadata":{"execution":{"iopub.status.busy":"2021-12-15T11:43:27.33859Z","iopub.execute_input":"2021-12-15T11:43:27.339014Z","iopub.status.idle":"2021-12-15T11:43:27.346782Z","shell.execute_reply.started":"2021-12-15T11:43:27.33898Z","shell.execute_reply":"2021-12-15T11:43:27.346284Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TRAIN_PATH = \"../input/petfinder-pawpularity-score/train/\"\nTEST_PATH = \"../input/petfinder-pawpularity-score/test/\"\n\ntrain_df['Width'], train_df['Heihgt'], train_df['Landscape'] = get_img_size(TRAIN_PATH)","metadata":{"execution":{"iopub.status.busy":"2021-12-15T11:43:27.347898Z","iopub.execute_input":"2021-12-15T11:43:27.348423Z","iopub.status.idle":"2021-12-15T11:45:12.33384Z","shell.execute_reply.started":"2021-12-15T11:43:27.348385Z","shell.execute_reply":"2021-12-15T11:45:12.333144Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-15T11:45:12.334994Z","iopub.execute_input":"2021-12-15T11:45:12.33572Z","iopub.status.idle":"2021-12-15T11:45:12.357226Z","shell.execute_reply.started":"2021-12-15T11:45:12.335679Z","shell.execute_reply":"2021-12-15T11:45:12.35639Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df['Width'], test_df['Heihgt'], test_df['Landscape'] = get_img_size(TEST_PATH)\n\ntest_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-15T11:45:12.358578Z","iopub.execute_input":"2021-12-15T11:45:12.35891Z","iopub.status.idle":"2021-12-15T11:45:12.420886Z","shell.execute_reply.started":"2021-12-15T11:45:12.358874Z","shell.execute_reply":"2021-12-15T11:45:12.420218Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Final Training Data**\n\nWe will now define the final dataset. \nRemember we agreeed to remove Face due to the high multicollinearity.\nAlso, remember our target variable - Pawpularity is not normally distributed, hence we will normalise by dividing by 100","metadata":{}},{"cell_type":"code","source":"img = train_df[[\"Img\"]].values\ny = np.ravel(train_df[[\"Pawpularity\"]]/100)\nX = train_df.drop([\"Id\",\"Img\", \"Face\", \"Pawpularity\"], axis=1)\nX_test = test_df.drop([\"Id\", \"Face\", \"Img\"], axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-12-15T11:45:12.422171Z","iopub.execute_input":"2021-12-15T11:45:12.422894Z","iopub.status.idle":"2021-12-15T11:45:12.434692Z","shell.execute_reply.started":"2021-12-15T11:45:12.422854Z","shell.execute_reply":"2021-12-15T11:45:12.433654Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Normalization\n\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\n\nencoder = MinMaxScaler()\nencoder.fit(X)\nX_scaled = encoder.transform(X)\nX_scaled = pd.DataFrame(X_scaled, columns=X.columns)\n\nX_test_scaled = encoder.transform(X_test)\nX_test_scaled = pd.DataFrame(X_test_scaled, columns=X_test.columns)","metadata":{"execution":{"iopub.status.busy":"2021-12-15T11:45:12.436745Z","iopub.execute_input":"2021-12-15T11:45:12.437354Z","iopub.status.idle":"2021-12-15T11:45:12.449804Z","shell.execute_reply.started":"2021-12-15T11:45:12.437314Z","shell.execute_reply":"2021-12-15T11:45:12.449037Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Now we will use RandomForest to determine feature importance and GridSearchCV to find best hypeparameter**","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=38)\n\nprint(f'X_train: {X_train.shape}')\nprint(f'X_valid: {X_valid.shape}')\nprint(f'y_train: {y_train.shape}')\nprint(f'y_valid: {y_valid.shape}')","metadata":{"execution":{"iopub.status.busy":"2021-12-15T11:45:12.453155Z","iopub.execute_input":"2021-12-15T11:45:12.454896Z","iopub.status.idle":"2021-12-15T11:45:12.465602Z","shell.execute_reply.started":"2021-12-15T11:45:12.454864Z","shell.execute_reply":"2021-12-15T11:45:12.464863Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import GridSearchCV\n\nregressor = RandomForestRegressor(random_state=8)\nparam_grid = {\n            \"n_estimators\" : [10,20,50,75,100,150],\n            \"max_features\" : [\"log2\", \"sqrt\"],\n            \"max_depth\"    : [5,10,15,25,35,50],\n            \"bootstrap\"    : [True, False]\n        }\n\ngrid_reg = GridSearchCV(\n    regressor,\n    param_grid,\n    cv = 5,\n    verbose=1,\n    n_jobs=-1)\n\nbest_reg = grid_reg.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2021-12-15T11:45:12.467336Z","iopub.execute_input":"2021-12-15T11:45:12.467601Z","iopub.status.idle":"2021-12-15T11:51:31.092678Z","shell.execute_reply.started":"2021-12-15T11:45:12.467557Z","shell.execute_reply":"2021-12-15T11:51:31.091955Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"The best parameters for the model is: \\n {best_reg.best_params_}\")","metadata":{"execution":{"iopub.status.busy":"2021-12-15T11:51:31.094074Z","iopub.execute_input":"2021-12-15T11:51:31.09489Z","iopub.status.idle":"2021-12-15T11:51:31.100087Z","shell.execute_reply.started":"2021-12-15T11:51:31.094844Z","shell.execute_reply":"2021-12-15T11:51:31.099379Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Save the Best Parameter model**","metadata":{}},{"cell_type":"code","source":"import pickle\n\nwith open('best_randforst_param.sav', 'wb') as best_randforst_param:\n    pickle.dump(best_reg, best_randforst_param)\n    \n    \n\n# loaded_model = pickle.load(open(filename, 'rb'))","metadata":{"execution":{"iopub.status.busy":"2021-12-15T11:51:31.101284Z","iopub.execute_input":"2021-12-15T11:51:31.101877Z","iopub.status.idle":"2021-12-15T11:51:31.113883Z","shell.execute_reply.started":"2021-12-15T11:51:31.101836Z","shell.execute_reply":"2021-12-15T11:51:31.113201Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now, we will plot the importance of features in the modeling:","metadata":{}},{"cell_type":"code","source":"importances = best_reg.best_estimator_.feature_importances_\n\nfeature_names = X_train.columns\nforest_importances = pd.DataFrame(importances, columns=[\"FI\"], index=feature_names)\nforest_importances = forest_importances.sort_values(\"FI\", ascending=False)\n\nfig, ax = plt.subplots()\nsns.barplot(data=forest_importances, x = \"FI\", \n            y=forest_importances.index, ax=ax, \n            palette=\"Blues_d\")\nax.set_title(\"Feature importances of RandomForestRegressor\", fontweight='bold')\nax.set_xlabel(\"Mean decrease in impurity\")\nax.set_ylabel(\"Features\")\nfig.tight_layout()","metadata":{"execution":{"iopub.status.busy":"2021-12-15T11:51:31.116154Z","iopub.execute_input":"2021-12-15T11:51:31.116941Z","iopub.status.idle":"2021-12-15T11:51:31.572727Z","shell.execute_reply.started":"2021-12-15T11:51:31.116876Z","shell.execute_reply":"2021-12-15T11:51:31.572059Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Now let us use this random Forest model to perform prediction on the validation set**","metadata":{}},{"cell_type":"code","source":"pred_reg = best_reg.predict(X_valid)","metadata":{"execution":{"iopub.status.busy":"2021-12-15T11:51:31.573978Z","iopub.execute_input":"2021-12-15T11:51:31.574331Z","iopub.status.idle":"2021-12-15T11:51:31.589427Z","shell.execute_reply.started":"2021-12-15T11:51:31.574291Z","shell.execute_reply":"2021-12-15T11:51:31.58874Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(figsize=(12,8))\nplt.scatter(x=pred_reg, y=y_valid)\nplt.ylabel(\"Pawpularity real values (y_valid)\")\nplt.xlabel(\"Predicted values (rfr_pred)\")\nplt.title(\"Predicted Pawpularity VS True values with RandomForest\", \n          fontsize=15, fontweight='bold')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-15T11:51:31.590588Z","iopub.execute_input":"2021-12-15T11:51:31.591165Z","iopub.status.idle":"2021-12-15T11:51:31.863701Z","shell.execute_reply.started":"2021-12-15T11:51:31.591126Z","shell.execute_reply":"2021-12-15T11:51:31.863054Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import mean_squared_error, r2_score\n\nprint(f\"Mean Squared Error: {mean_squared_error(y_valid, pred_reg)}\")\nprint(f\"R Squared Score: {r2_score(y_valid, pred_reg)}\")","metadata":{"execution":{"iopub.status.busy":"2021-12-15T11:51:31.864924Z","iopub.execute_input":"2021-12-15T11:51:31.865375Z","iopub.status.idle":"2021-12-15T11:51:31.872094Z","shell.execute_reply.started":"2021-12-15T11:51:31.865332Z","shell.execute_reply":"2021-12-15T11:51:31.871397Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From the above, especially the R-Squared score, it shows the model did very bad (Worst). This means the dataset alone is not enough predictor of popularity\n\n**We will now use Image claffication with NASNetLarge**","metadata":{}},{"cell_type":"code","source":"# lad the Keras model NASNetLarge\n\nnasnet_model = tf.keras.applications.NASNetLarge(\n    include_top=False,\n    weights=None,\n    input_tensor=None,\n    input_shape=(299,299,3),\n    pooling='avg'\n)\n\nnasnet_model.load_weights('../input/keras-applications-models/NASNetLarge.h5')\n\n# Non trainable\nnasnet_model.trainable = False","metadata":{"execution":{"iopub.status.busy":"2021-12-15T11:51:31.873283Z","iopub.execute_input":"2021-12-15T11:51:31.873679Z","iopub.status.idle":"2021-12-15T11:51:45.572425Z","shell.execute_reply.started":"2021-12-15T11:51:31.873641Z","shell.execute_reply":"2021-12-15T11:51:45.571667Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"For better use in Keras, we will create generators by slightly modifying our DataFrame Pandas. We will indeed add the name (and extension) of the image files to our y DataSets.","metadata":{}},{"cell_type":"code","source":"k_df = train_df[[\"Id\",\"Pawpularity\"]]\nk_df[\"Image\"] = k_df[\"Id\"].apply(lambda x: x+\".jpg\")\nk_df[\"Pawpularity\"] = k_df[\"Pawpularity\"]/100\nk_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-15T11:51:45.57379Z","iopub.execute_input":"2021-12-15T11:51:45.574053Z","iopub.status.idle":"2021-12-15T11:51:45.594919Z","shell.execute_reply.started":"2021-12-15T11:51:45.574018Z","shell.execute_reply":"2021-12-15T11:51:45.594145Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"k_X_train, k_X_valid, k_y_train, k_y_valid = train_test_split(\n    k_df[\"Image\"], k_df[\"Pawpularity\"], \n    test_size=0.2, \n    random_state=38)\n\nprint(f\"X_train : {k_X_train.shape}\")\nprint(f\"X_test : {k_X_valid.shape}\")\nprint(f\"y_train : {k_y_train.shape[0]}\")\nprint(f\"y_test : {k_y_valid.shape[0]}\")","metadata":{"execution":{"iopub.status.busy":"2021-12-15T11:51:45.596288Z","iopub.execute_input":"2021-12-15T11:51:45.596554Z","iopub.status.idle":"2021-12-15T11:51:45.608648Z","shell.execute_reply.started":"2021-12-15T11:51:45.596514Z","shell.execute_reply":"2021-12-15T11:51:45.607859Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"k_train_df = pd.DataFrame(k_X_train, columns=[\"Image\"])\nk_train_df[\"Pawpularity\"] = k_y_train\nk_valid_df = pd.DataFrame(k_X_valid, columns=[\"Image\"])\nk_valid_df[\"Pawpularity\"] = k_y_valid","metadata":{"execution":{"iopub.status.busy":"2021-12-15T11:51:45.609859Z","iopub.execute_input":"2021-12-15T11:51:45.611347Z","iopub.status.idle":"2021-12-15T11:51:45.620406Z","shell.execute_reply.started":"2021-12-15T11:51:45.611305Z","shell.execute_reply":"2021-12-15T11:51:45.619607Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"k_train_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-15T11:51:45.621931Z","iopub.execute_input":"2021-12-15T11:51:45.622202Z","iopub.status.idle":"2021-12-15T11:51:45.634279Z","shell.execute_reply.started":"2021-12-15T11:51:45.622164Z","shell.execute_reply":"2021-12-15T11:51:45.633563Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n    preprocessing_function=tf.keras.applications.nasnet.preprocess_input,\n    validation_split=0.2)\ntest_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n    preprocessing_function=tf.keras.applications.nasnet.preprocess_input)","metadata":{"execution":{"iopub.status.busy":"2021-12-15T11:51:45.635476Z","iopub.execute_input":"2021-12-15T11:51:45.635829Z","iopub.status.idle":"2021-12-15T11:51:45.64168Z","shell.execute_reply.started":"2021-12-15T11:51:45.635789Z","shell.execute_reply":"2021-12-15T11:51:45.640771Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_generator = datagen.flow_from_dataframe(\n    dataframe=k_train_df,\n    directory=dataset_path+\"train/\",\n    x_col=\"Image\",\n    y_col=\"Pawpularity\",\n    subset=\"training\",\n    target_size=(299,299),\n    batch_size=32,\n    seed=42,\n    shuffle=True,\n    class_mode=\"raw\")\n\nvalid_generator = datagen.flow_from_dataframe(\n    dataframe=k_train_df,\n    directory=dataset_path+\"train/\",\n    x_col=\"Image\",\n    y_col=\"Pawpularity\",\n    subset=\"validation\",\n    target_size=(299,299),\n    batch_size=32,\n    seed=42,\n    shuffle=True,\n    class_mode=\"raw\")\n\ntest_generator = datagen.flow_from_dataframe(\n    dataframe=k_valid_df,\n    directory=dataset_path+\"train/\",\n    x_col=\"Image\",\n    y_col=\"Pawpularity\",\n    target_size=(299,299),\n    batch_size=32,\n    seed=42,\n    shuffle=True,\n    class_mode=\"raw\")","metadata":{"execution":{"iopub.status.busy":"2021-12-15T11:51:45.643549Z","iopub.execute_input":"2021-12-15T11:51:45.643895Z","iopub.status.idle":"2021-12-15T11:51:48.989769Z","shell.execute_reply.started":"2021-12-15T11:51:45.643793Z","shell.execute_reply":"2021-12-15T11:51:48.988899Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Add new fully-connected layers\nbase_output = nasnet_model.output\nbase_output = Dense(128, activation='relu')(base_output)\nbase_output = Dropout(0.2)(base_output)\nbase_output = Dense(256, activation='relu')(base_output)\nbase_output = Dense(128, activation='relu')(base_output)\nbase_output = Dropout(0.2)(base_output)\n# Output : new classifier\npredictions = Dense(1, activation='linear')(base_output)\n\n# Define new model\nmy_nasnet_model = Model(inputs=nasnet_model.input, outputs=predictions)\nmy_nasnet_model.compile(optimizer=\"adam\", loss=tf.keras.metrics.mean_squared_error)","metadata":{"execution":{"iopub.status.busy":"2021-12-15T11:51:48.990893Z","iopub.execute_input":"2021-12-15T11:51:48.991136Z","iopub.status.idle":"2021-12-15T11:51:49.109361Z","shell.execute_reply.started":"2021-12-15T11:51:48.991099Z","shell.execute_reply":"2021-12-15T11:51:49.108658Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"STEP_SIZE_TRAIN = train_generator.n//train_generator.batch_size\nSTEP_SIZE_VALID = valid_generator.n//valid_generator.batch_size\n\n# Early Stopping to prevent overfitting\nearly_stopper = tf.keras.callbacks.EarlyStopping(\n    monitor=\"val_loss\", \n    patience=15, \n    verbose=3, \n    restore_best_weights=True)\n\n\nhistory_nasnet = my_nasnet_model.fit(\n    train_generator,\n    steps_per_epoch=STEP_SIZE_TRAIN,\n    validation_data=valid_generator,\n    validation_steps=STEP_SIZE_VALID,\n    epochs=50,\n    verbose=2,\n    callbacks=[early_stopper])","metadata":{"execution":{"iopub.status.busy":"2021-12-15T11:51:49.1105Z","iopub.execute_input":"2021-12-15T11:51:49.110745Z","iopub.status.idle":"2021-12-15T12:34:46.97697Z","shell.execute_reply.started":"2021-12-15T11:51:49.110711Z","shell.execute_reply":"2021-12-15T12:34:46.976181Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(figsize=(12, 8))\nplt.plot(history_nasnet.history[\"loss\"],\n         color=\"#186fb4\", linestyle=\"-.\",\n         label=\"Train\")\nplt.plot(history_nasnet.history[\"val_loss\"],\n         color=\"#186fb4\",\n         label=\"Validation\")\nplt.legend()\nplt.title(\"RMSE metric of NasNetLarge model for Pawpularity\", \n          fontsize=20, fontweight='bold')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-15T12:34:46.981143Z","iopub.execute_input":"2021-12-15T12:34:46.983149Z","iopub.status.idle":"2021-12-15T12:34:47.579172Z","shell.execute_reply.started":"2021-12-15T12:34:46.983107Z","shell.execute_reply":"2021-12-15T12:34:47.578476Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From the above, we see a downward slope of the training loss but the validation barely dropped. Lets try predicting","metadata":{}},{"cell_type":"code","source":"nasnet_pred = my_nasnet_model.predict(test_generator)\nnasnet_pred.shape","metadata":{"execution":{"iopub.status.busy":"2021-12-15T13:02:41.56476Z","iopub.execute_input":"2021-12-15T13:02:41.565024Z","iopub.status.idle":"2021-12-15T13:03:18.57182Z","shell.execute_reply.started":"2021-12-15T13:02:41.564994Z","shell.execute_reply":"2021-12-15T13:03:18.571078Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(figsize=(12,8))\nplt.scatter(x=nasnet_pred, y=k_y_valid)\nplt.ylabel(\"Pawpularity real values (k_y_valid)\")\nplt.xlabel(\"Predicted values (nasnet_pred)\")\nplt.title(\"Predicted Pawpularity VS True values with NasnetLarge\", \n          fontsize=20, fontweight='bold')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-15T13:04:22.735427Z","iopub.execute_input":"2021-12-15T13:04:22.736274Z","iopub.status.idle":"2021-12-15T13:04:23.0127Z","shell.execute_reply.started":"2021-12-15T13:04:22.736223Z","shell.execute_reply":"2021-12-15T13:04:23.012041Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"R Squared Score: {r2_score(k_y_valid, nasnet_pred)}\")","metadata":{"execution":{"iopub.status.busy":"2021-12-15T13:05:17.608728Z","iopub.execute_input":"2021-12-15T13:05:17.609321Z","iopub.status.idle":"2021-12-15T13:05:17.614987Z","shell.execute_reply.started":"2021-12-15T13:05:17.609281Z","shell.execute_reply":"2021-12-15T13:05:17.613992Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Again from the above, the model did poorly (though better than the RandomForest Model). Hence the model alone is not enough to predict the target value.\n\nWe will now try optimizing our model ","metadata":{}},{"cell_type":"markdown","source":"# Transfer Learning Optimization","metadata":{}},{"cell_type":"code","source":"datagen_2 = tf.keras.preprocessing.image.ImageDataGenerator(\n    rotation_range=20, # rotation\n    width_shift_range=0.2, # horizontal shift\n    height_shift_range=0.2, # vertical shift\n    zoom_range=0.2, # zoom\n    horizontal_flip=True, # horizontal flip\n    featurewise_std_normalization=True,\n    preprocessing_function=tf.keras.applications.xception.preprocess_input,\n    validation_split=0.2)","metadata":{"execution":{"iopub.status.busy":"2021-12-15T13:53:32.191344Z","iopub.execute_input":"2021-12-15T13:53:32.192051Z","iopub.status.idle":"2021-12-15T13:53:32.200657Z","shell.execute_reply.started":"2021-12-15T13:53:32.192011Z","shell.execute_reply":"2021-12-15T13:53:32.199833Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_generator_2 = datagen_2.flow_from_dataframe(\n    dataframe=k_train_df,\n    directory=dataset_path+\"train/\",\n    x_col=\"Image\",\n    y_col=\"Pawpularity\",\n    subset=\"training\",\n    target_size=(299,299),\n    batch_size=32,\n    seed=42,\n    shuffle=True,\n    class_mode=\"raw\")\n\nvalid_generator_2 = datagen_2.flow_from_dataframe(\n    dataframe=k_train_df,\n    directory=dataset_path+\"train/\",\n    x_col=\"Image\",\n    y_col=\"Pawpularity\",\n    subset=\"validation\",\n    target_size=(299,299),\n    batch_size=32,\n    seed=42,\n    shuffle=True,\n    class_mode=\"raw\")","metadata":{"execution":{"iopub.status.busy":"2021-12-15T13:55:01.718627Z","iopub.execute_input":"2021-12-15T13:55:01.7194Z","iopub.status.idle":"2021-12-15T13:55:04.344867Z","shell.execute_reply.started":"2021-12-15T13:55:01.719349Z","shell.execute_reply":"2021-12-15T13:55:04.344133Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"STEP_SIZE_TRAIN = train_generator_2.n//train_generator_2.batch_size\nSTEP_SIZE_VALID = valid_generator_2.n//valid_generator_2.batch_size","metadata":{"execution":{"iopub.status.busy":"2021-12-15T13:55:39.554687Z","iopub.execute_input":"2021-12-15T13:55:39.554947Z","iopub.status.idle":"2021-12-15T13:55:39.55858Z","shell.execute_reply.started":"2021-12-15T13:55:39.554917Z","shell.execute_reply":"2021-12-15T13:55:39.55791Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf.keras.backend.clear_session()\nhistory_nasnet_2 = my_nasnet_model.fit(\n    train_generator_2,\n    steps_per_epoch=STEP_SIZE_TRAIN,\n    validation_data=valid_generator_2,\n    validation_steps=STEP_SIZE_VALID,\n    epochs=50,\n    verbose=2,\n    callbacks=[early_stopper])","metadata":{"execution":{"iopub.status.busy":"2021-12-15T13:57:51.188271Z","iopub.execute_input":"2021-12-15T13:57:51.18885Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(figsize=(12, 7))\nplt.plot(history_nasnet_2.history[\"loss\"],\n         color=\"#186fb4\", linestyle=\"-.\",\n         label=\"Train\")\nplt.plot(history_nasnet_2.history[\"val_loss\"],\n         color=\"#186fb4\",\n         label=\"Validation\")\nplt.legend()\nplt.title(\"RMSE metric of Xception augmented model for Pawpularity\", \n          fontsize=20, fontweight='bold')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-15T16:12:31.120778Z","iopub.execute_input":"2021-12-15T16:12:31.121043Z","iopub.status.idle":"2021-12-15T16:12:31.392683Z","shell.execute_reply.started":"2021-12-15T16:12:31.121011Z","shell.execute_reply":"2021-12-15T16:12:31.392024Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nasnet_pred_2 = history_nasnet_2.model.predict(test_generator)\nnasnet_pred_2.shape","metadata":{"execution":{"iopub.status.busy":"2021-12-15T16:13:57.117964Z","iopub.execute_input":"2021-12-15T16:13:57.118277Z","iopub.status.idle":"2021-12-15T16:14:30.626873Z","shell.execute_reply.started":"2021-12-15T16:13:57.118241Z","shell.execute_reply":"2021-12-15T16:14:30.626105Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(figsize=(12,8))\nplt.scatter(x=nasnet_pred_2, y=k_y_valid)\nplt.ylabel(\"Pawpularity real values (k_y_valid)\")\nplt.xlabel(\"Predicted values (xcept_pred)\")\nplt.title(\"Predicted Pawpularity VS True values with Xception\", \n          fontsize=20, fontweight='bold')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-15T16:14:41.213069Z","iopub.execute_input":"2021-12-15T16:14:41.213424Z","iopub.status.idle":"2021-12-15T16:14:41.58375Z","shell.execute_reply.started":"2021-12-15T16:14:41.213382Z","shell.execute_reply":"2021-12-15T16:14:41.579309Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"R Squared Score: {r2_score(k_y_valid, nasnet_pred_2)}\")","metadata":{"execution":{"iopub.status.busy":"2021-12-15T16:15:10.971087Z","iopub.execute_input":"2021-12-15T16:15:10.971366Z","iopub.status.idle":"2021-12-15T16:15:10.976789Z","shell.execute_reply.started":"2021-12-15T16:15:10.971336Z","shell.execute_reply":"2021-12-15T16:15:10.976053Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The augmented model looks a bit better but still fails to predict popularity scores reliably enough","metadata":{}},{"cell_type":"markdown","source":"# Hybrid approach with feature detection and RandomForest\n\nWe are therefore going to use a hybrid approach consisting in carrying out the feature detection with NASNetLarge, then in coupling the results with the database of image characteristics to finally predict y with a RandomForestRegressor.","metadata":{}},{"cell_type":"code","source":"def feature_detect_img(folder, img_size=299):\n    listVectors = []\n    for img in tqdm(os.listdir(dataset_path+folder+\"/\")):\n        image = plt.imread(dataset_path+folder+\"/\"+img)\n        #resize image if new dims provided\n        image = cv2.resize(image, (img_size,img_size),\n                           interpolation = cv2.INTER_AREA)\n        image = np.expand_dims(image, axis=0)\n        image = tf.keras.applications.nasnet.preprocess_input(image)\n        \n        img_vector = nasnet_model.predict(image)\n        listVectors.append(np.array(img_vector))\n    \n    return listVectors","metadata":{"execution":{"iopub.status.busy":"2021-12-15T16:22:55.733576Z","iopub.execute_input":"2021-12-15T16:22:55.734377Z","iopub.status.idle":"2021-12-15T16:22:55.740925Z","shell.execute_reply.started":"2021-12-15T16:22:55.734327Z","shell.execute_reply":"2021-12-15T16:22:55.740247Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_vectors_fd = feature_detect_img(\"train\", img_size=299)","metadata":{"execution":{"iopub.status.busy":"2021-12-15T16:24:51.936133Z","iopub.execute_input":"2021-12-15T16:24:51.93684Z","iopub.status.idle":"2021-12-15T16:40:59.334881Z","shell.execute_reply.started":"2021-12-15T16:24:51.936803Z","shell.execute_reply":"2021-12-15T16:40:59.334092Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_vectors_fd = np.array(train_vectors_fd)\ntrain_vectors_fd = np.squeeze(train_vectors_fd)\ntrain_vectors_fd.shape\ntrain_vectors_fd = pd.DataFrame(train_vectors_fd)","metadata":{"execution":{"iopub.status.busy":"2021-12-15T16:54:52.651803Z","iopub.execute_input":"2021-12-15T16:54:52.652068Z","iopub.status.idle":"2021-12-15T16:54:52.720219Z","shell.execute_reply.started":"2021-12-15T16:54:52.652037Z","shell.execute_reply":"2021-12-15T16:54:52.719477Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hy_train_df = pd.concat([train_df,train_vectors_fd], axis=1)\nhy_train_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-15T16:55:44.934573Z","iopub.execute_input":"2021-12-15T16:55:44.934833Z","iopub.status.idle":"2021-12-15T16:55:45.139994Z","shell.execute_reply.started":"2021-12-15T16:55:44.934804Z","shell.execute_reply":"2021-12-15T16:55:45.139175Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hy_train_df.columns","metadata":{"execution":{"iopub.status.busy":"2021-12-15T16:58:34.854082Z","iopub.execute_input":"2021-12-15T16:58:34.855057Z","iopub.status.idle":"2021-12-15T16:58:34.865511Z","shell.execute_reply.started":"2021-12-15T16:58:34.855012Z","shell.execute_reply":"2021-12-15T16:58:34.864488Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"h_labels = hy_train_df[\"Id\"]\nh_y = hy_train_df[\"Pawpularity\"]\nh_X = hy_train_df.drop([\"Id\",\"Pawpularity\", \"Img\"], axis=1)\n\n# Normalization\nencoder = MinMaxScaler()\nencoder.fit(h_X)\nh_X_scaled = encoder.transform(h_X)\nh_X_scaled = pd.DataFrame(h_X_scaled, columns=h_X.columns)\n\nh_X_train, h_X_valid, h_y_train, h_y_valid = train_test_split(\n    h_X_scaled, h_y, test_size=0.3, random_state=38)","metadata":{"execution":{"iopub.status.busy":"2021-12-15T16:57:12.999792Z","iopub.execute_input":"2021-12-15T16:57:13.000399Z","iopub.status.idle":"2021-12-15T16:57:15.732755Z","shell.execute_reply.started":"2021-12-15T16:57:13.000355Z","shell.execute_reply":"2021-12-15T16:57:15.731729Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"X_train : {h_X_train.shape}\")\nprint(f\"X_test : {h_X_valid.shape}\")\nprint(f\"y_train : {h_y_train.shape[0]}\")\nprint(f\"y_test : {h_y_valid.shape[0]}\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"h_rfr = RandomForestRegressor(random_state=8)\nparam_grid = {\n            \"n_estimators\" : [10,50, 75, 100, 150],\n            \"max_features\" : [\"log2\", \"sqrt\"],\n            \"max_depth\"    : [5,15,25, 35, 50],\n            \"bootstrap\"    : [True, False]\n        }\n\nh_grid_rfr = GridSearchCV(\n    h_rfr,\n    param_grid,\n    cv = 5,\n    verbose=2,\n    n_jobs=-1)\n\nh_best_rfr = h_grid_rfr.fit(h_X_train, h_y_train)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"The best parameters for Randomforest: {h_best_rfr.best_params_}\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"h_rfr_pred = h_best_rfr.predict(h_X_valid)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(figsize=(12,8))\nplt.scatter(x=h_rfr_pred, y=h_y_valid)\nplt.ylabel(\"Pawpularity real values (y_valid)\")\nplt.xlabel(\"Predicted values (rfr_pred)\")\nplt.title(\"Predicted Pawpularity VS True values with RandomForest\", \n          fontsize=20, fontweight='bold')\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_df = pd.read_csv(\"\".join([dataset_path,\"test.csv\"]))\nsubmission_df = submission_df[[\"Id\"]]\nsubmission_df[\"Image\"] =  submission_df[\"Id\"].apply(lambda x: x+\".jpg\")\n\nsubmission_generator = test_datagen.flow_from_dataframe(\n    dataframe=submission_df,\n    directory=dataset_path+\"test/\",\n    x_col=\"Image\",\n    y_col=None,\n    target_size=(299,299),\n    batch_size=32,\n    seed=42,\n    shuffle=False,\n    class_mode=None)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_pred = my_nasnet_model.predict(submission_generator)\nsubmission_pred.shape","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_vectors_fd = feature_detect_img(\"test\", img_size=299)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_vectors_fd = np.array(test_vectors_fd)\ntest_vectors_fd = np.squeeze(test_vectors_fd)\ntest_vectors_fd.shape\ntest_vectors_fd = pd.DataFrame(test_vectors_fd)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hy_test_df = pd.concat([test_df,test_vectors_fd], axis=1)\nhy_test_df.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"h_test_labels = hy_test_df[\"Id\"]\nh_X_test = hy_test_df.drop(\"Id\", axis=1)\nh_X_test_scaled = encoder.transform(h_X_test)\nh_X_test_scaled = pd.DataFrame(h_X_test_scaled, columns=h_X_test.columns)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_pred = h_best_rfr.predict(h_X_test_scaled)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(figsize=(10,7))\nplt.hist((submission_pred))\nplt.xlabel(\"Pawpularity Score\")\nplt.ylabel(\"number of individuals\")\nplt.title(\"Distribution of predicted submission results\", \n          fontsize=20, fontweight='bold')\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_df[\"Pawpularity\"] = (submission_pred)\nsubmission_df = submission_df[[\"Id\",\"Pawpularity\"]]\nsubmission_df.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_df.to_csv(\"submission.csv\", sep=\",\", index=False)","metadata":{},"execution_count":null,"outputs":[]}]}